# kafka-backup-demos Docker Compose
# Based on: https://github.com/osodevops/kafka-backup/blob/main/docker-compose.yml
#
# Usage:
#   docker compose up -d                    # Start all services
#   docker compose --profile tools run --rm kafka-backup <command>
#   docker compose down                     # Stop all services

networks:
  kafka-net:
    driver: bridge

volumes:
  minio-data:

services:
  # Apache Kafka Broker (KRaft mode - no Zookeeper)
  kafka-broker-1:
    image: apache/kafka:3.7.1
    hostname: kafka-broker-1
    container_name: kafka-broker-1
    restart: always
    networks:
      - kafka-net
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1001
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_LISTENERS: PLAINTEXT://kafka-broker-1:9094,EXTERNAL://kafka-broker-1:9092,CONTROLLER://kafka-broker-1:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-broker-1:9094,EXTERNAL://kafka-broker-1:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_PROCESS_ROLES: controller,broker
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1001@kafka-broker-1:9093
      KAFKA_LOG_DIRS: /tmp/kafka-logs
      AUTO_CREATE_TOPICS_ENABLE: 'false'
      # Allow large messages (up to 15MB) for large-messages demo
      KAFKA_MESSAGE_MAX_BYTES: 15728640
      KAFKA_REPLICA_FETCH_MAX_BYTES: 15728640

  # Topic setup helper - creates all demo topics
  kafka-setup:
    image: bitnami/kafka:3.7.1
    hostname: kafka-setup
    networks:
      - kafka-net
    depends_on:
      - kafka-broker-1
    restart: on-failure
    command: >
      bash -c 'echo "Waiting for Kafka to be ready..." &&
      sleep 10 &&
      echo "Creating demo topics..." &&
      kafka-topics.sh --create --if-not-exists --bootstrap-server kafka-broker-1:9092 --partitions 3 --replication-factor 1 --topic test-topic &&
      kafka-topics.sh --create --if-not-exists --bootstrap-server kafka-broker-1:9092 --partitions 3 --replication-factor 1 --topic orders &&
      kafka-topics.sh --create --if-not-exists --bootstrap-server kafka-broker-1:9092 --partitions 3 --replication-factor 1 --topic payments &&
      kafka-topics.sh --create --if-not-exists --bootstrap-server kafka-broker-1:9092 --partitions 3 --replication-factor 1 --topic events &&
      kafka-topics.sh --create --if-not-exists --bootstrap-server kafka-broker-1:9092 --partitions 3 --replication-factor 1 --topic orders_enriched &&
      kafka-topics.sh --create --if-not-exists --bootstrap-server kafka-broker-1:9092 --partitions 1 --replication-factor 1 --topic large_messages --config max.message.bytes=15728640 &&
      echo "All demo topics created successfully"'

  # MinIO (S3-compatible storage)
  minio:
    image: minio/minio:latest
    hostname: minio
    container_name: minio
    networks:
      - kafka-net
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9001"
    volumes:
      - minio-data:/data

  # MinIO bucket setup
  minio-setup:
    image: minio/mc:latest
    networks:
      - kafka-net
    depends_on:
      - minio
    restart: on-failure
    entrypoint: >
      /bin/sh -c "
      sleep 5;
      mc alias set local http://minio:9000 minioadmin minioadmin;
      mc mb local/kafka-backups --ignore-existing;
      echo 'Bucket kafka-backups created';
      "

  # Kafka CLI tools (for running kafka-console-producer, kafka-console-consumer, etc.)
  kafka-cli:
    image: bitnami/kafka:3.7.1
    hostname: kafka-cli
    networks:
      - kafka-net
    depends_on:
      - kafka-broker-1
    environment:
      KAFKA_BROKER: kafka-broker-1:9092
    volumes:
      - ./data:/data
      - ./config:/config
    profiles:
      - tools
    entrypoint: ["tail", "-f", "/dev/null"]

  # Kafka Backup CLI
  # Option 1: Use published image (when available)
  # image: osodevops/kafka-backup:latest
  # Option 2: Build from local kafka-backup repo
  kafka-backup:
    build:
      context: ../kafka-backup
      dockerfile: Dockerfile
    networks:
      - kafka-net
    environment:
      KAFKA_BROKERS: kafka-broker-1:9092
      S3_ENDPOINT: http://minio:9000
      S3_ACCESS_KEY: minioadmin
      S3_SECRET_KEY: minioadmin
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
      RUST_LOG: info
    depends_on:
      - kafka-broker-1
      - minio
    volumes:
      - ./config:/config
      - ./data:/data
    profiles:
      - tools
